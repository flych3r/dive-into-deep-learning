{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tensorflow running on CPU\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from d2l.tensorflow import config, data, initializers, activations, losses, metrics, optimizers, plot\n",
    "\n",
    "config.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_iter, test_iter = data.load_tfds_dataset('fashion_mnist', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, learning_rate = 10, 0.5\n",
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "\n",
    "loss_function = losses.softmax_cross_entropy\n",
    "eval_metric = metrics.accuracy\n",
    "optimizer = optimizers.sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLayer:\n",
    "    _identifier = -1\n",
    "    __type__ = 'base'\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(BaseLayer):\n",
    "    def __init__(\n",
    "        self, n_inputs, n_outputs, activation='relu',\n",
    "        initialization='gaussian', scale=None, sigma=None\n",
    "    ):\n",
    "        Dense.__type__ = 'compute'\n",
    "        Dense._identifier += 1\n",
    "        self.__name__ = '{}_{}'.format(Dense.__name__, Dense._identifier).lower()\n",
    "\n",
    "        self.weights, self.bias = initializers.initialize_parameters(\n",
    "            n_inputs, n_outputs, initialization, scale, sigma\n",
    "        )\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.activation = activations.get_activation(activation)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str({\n",
    "            'name': self.__name__,\n",
    "            'type': self.__type__,\n",
    "            'n_inputs': self.n_inputs,\n",
    "            'n_outputs': self.n_outputs,\n",
    "            'activation': self.activation.__name__,\n",
    "            'weights': self.weights.numpy(),\n",
    "            'bias': self.bias.numpy()\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    _identifier = -1\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_function = None\n",
    "        self.eval_metric = None\n",
    "        self.eval_function = None\n",
    "        self.optimizer = None\n",
    "        self.compiled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(BaseModel):\n",
    "    def __init__(self):\n",
    "        super(Sequential, self).__init__()\n",
    "        Sequential._identifier += 1\n",
    "        self.__name__ = '{}_{}'.format(\n",
    "            Sequential.__name__, Sequential._identifier\n",
    "        ).lower()\n",
    "        self.layers = list()\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def compile(self, loss_function, eval_metric, optimizer):\n",
    "        self.loss_function = loss_function\n",
    "        self.eval_metric = eval_metric\n",
    "        self.optimizer = optimizer\n",
    "        self.compiled = True\n",
    "\n",
    "    def net(self, X, inference=False):\n",
    "        X = tf.reshape(X, (-1, self.layers[0].n_inputs))\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            X = layer.activation(tf.matmul(X, layer.weights) + layer.bias)\n",
    "\n",
    "        return tf.matmul(X, self.layers[-1].weights) + self.layers[-1].bias\n",
    "\n",
    "    def fit(self, epochs, train_iter, val_iter, learning_rate, batch_size, animate=False):\n",
    "        animator = None\n",
    "        if animate:\n",
    "            animator = plot.Animator(\n",
    "                xlabel='epoch', xlim=[1, epochs], ylim=[0, 1],\n",
    "                legend=['train loss', 'train eval', 'val loss', 'val eval'],\n",
    "                title='Training loss and eval'\n",
    "            )\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            metric_train = metrics.Accumulator(3)\n",
    "            W = [layer.weights for layer in self.layers]\n",
    "            b = [layer.bias for layer in self.layers]\n",
    "\n",
    "            for X, y in train_iter:\n",
    "                with tf.GradientTape() as t:\n",
    "                    y_hat = self.net(X)\n",
    "                    loss = self.loss_function(y, y_hat)\n",
    "                dW, db = t.gradient(loss, [W, b])\n",
    "                self.optimizer(W, b, dW, db, learning_rate, batch_size)\n",
    "                metric_train.add(\n",
    "                    tf.reduce_sum(loss), self.eval_metric(y, y_hat), y.shape[0]\n",
    "                )\n",
    "\n",
    "            train_metrics = (\n",
    "                metric_train[0] / metric_train[2],\n",
    "                metric_train[1] / metric_train[2]\n",
    "            )\n",
    "            val_metrics = self.predict(val_iter)\n",
    "            if animator:\n",
    "                animator.add(epoch + 1, train_metrics + val_metrics)\n",
    "            else:\n",
    "                print(\n",
    "                    'epoch {0} => '\n",
    "                    '[train loss: {1[0]}, train eval: {1[1]}]'\n",
    "                    ' | '\n",
    "                    '[val loss: {2[0]}, val eval: {2[1]}]'.format(\n",
    "                        epoch + 1, train_metrics, val_metrics\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    def predict(self, test_iter):\n",
    "        metric_test = metrics.Accumulator(3)\n",
    "\n",
    "        for X, y in test_iter:\n",
    "            y_hat = self.net(X, inference=True)\n",
    "            loss = self.loss_function(y, y_hat)\n",
    "            metric_test.add(tf.reduce_sum(loss), self.eval_metric(y, y_hat), y.shape[0])\n",
    "\n",
    "        return metric_test[0] / metric_test[2], metric_test[1] / metric_test[2]\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.compiled:\n",
    "            return str({\n",
    "                'name': self.__name__,\n",
    "                'layers': self.layers,\n",
    "                'loss function': self.loss_function.__name__,\n",
    "                'eval metric': self.eval_metric.__name__,\n",
    "                'optimizer': self.optimizer.__name__\n",
    "            })\n",
    "        return str({\n",
    "            'name': self.__name__,\n",
    "            'layers': self.layers,\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = Dense(num_inputs, num_hiddens)\n",
    "d1 = Dense(num_hiddens, num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': 'dense_0', 'type': 'compute', 'n_inputs': 784, 'n_outputs': 256, 'activation': 'relu', 'weights': array([[ 0.10286564, -0.20242675, -0.13621886, ...,  0.0080618 ,\n         0.04048036,  0.02602621],\n       [-0.16428794,  0.09207241,  0.0825626 , ..., -0.03658118,\n        -0.0450652 ,  0.12473804],\n       [-0.1000337 ,  0.05609204,  0.05150723, ..., -0.14192116,\n         0.14169066, -0.20065205],\n       ...,\n       [-0.05866313, -0.0219347 , -0.02409595, ...,  0.14254047,\n         0.12858361, -0.00100724],\n       [ 0.10365319,  0.01138475,  0.03546103, ..., -0.10747639,\n         0.01589487, -0.08870988],\n       [ 0.11321858, -0.21262196,  0.22235206, ..., -0.02750733,\n        -0.1954495 , -0.06486427]], dtype=float32), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)}"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(d0)\n",
    "model.add(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': 'sequential_0', 'layers': [{'name': 'dense_0', 'type': 'compute', 'n_inputs': 784, 'n_outputs': 256, 'activation': 'relu', 'weights': array([[ 0.10286564, -0.20242675, -0.13621886, ...,  0.0080618 ,\n         0.04048036,  0.02602621],\n       [-0.16428794,  0.09207241,  0.0825626 , ..., -0.03658118,\n        -0.0450652 ,  0.12473804],\n       [-0.1000337 ,  0.05609204,  0.05150723, ..., -0.14192116,\n         0.14169066, -0.20065205],\n       ...,\n       [-0.05866313, -0.0219347 , -0.02409595, ...,  0.14254047,\n         0.12858361, -0.00100724],\n       [ 0.10365319,  0.01138475,  0.03546103, ..., -0.10747639,\n         0.01589487, -0.08870988],\n       [ 0.11321858, -0.21262196,  0.22235206, ..., -0.02750733,\n        -0.1954495 , -0.06486427]], dtype=float32), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)}, {'name': 'dense_1', 'type': 'compute', 'n_inputs': 256, 'n_outputs': 10, 'activation': 'relu', 'weights': array([[ 0.00406225,  0.10187922,  0.01500382, ...,  0.10504436,\n        -0.06284735,  0.0051859 ],\n       [ 0.1323512 ,  0.01945285,  0.06376914, ...,  0.16973773,\n        -0.08150937, -0.08741213],\n       [ 0.09221309,  0.03286867, -0.05453553, ...,  0.01407232,\n         0.07919285, -0.13035272],\n       ...,\n       [ 0.05674529,  0.09535521,  0.10715585, ...,  0.02326189,\n         0.14302342,  0.04148311],\n       [-0.06244363, -0.07746019, -0.16216885, ..., -0.12061435,\n        -0.1706651 ,  0.15139966],\n       [ 0.02855223,  0.03102918,  0.17409141, ..., -0.0047065 ,\n        -0.17995022,  0.03680726]], dtype=float32), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)}]}"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss_function, eval_metric, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': 'sequential_0', 'layers': [{'name': 'dense_0', 'type': 'compute', 'n_inputs': 784, 'n_outputs': 256, 'activation': 'relu', 'weights': array([[ 0.10286564, -0.20242675, -0.13621886, ...,  0.0080618 ,\n         0.04048036,  0.02602621],\n       [-0.16428794,  0.09207241,  0.0825626 , ..., -0.03658118,\n        -0.0450652 ,  0.12473804],\n       [-0.1000337 ,  0.05609204,  0.05150723, ..., -0.14192116,\n         0.14169066, -0.20065205],\n       ...,\n       [-0.05866313, -0.0219347 , -0.02409595, ...,  0.14254047,\n         0.12858361, -0.00100724],\n       [ 0.10365319,  0.01138475,  0.03546103, ..., -0.10747639,\n         0.01589487, -0.08870988],\n       [ 0.11321858, -0.21262196,  0.22235206, ..., -0.02750733,\n        -0.1954495 , -0.06486427]], dtype=float32), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)}, {'name': 'dense_1', 'type': 'compute', 'n_inputs': 256, 'n_outputs': 10, 'activation': 'relu', 'weights': array([[ 0.00406225,  0.10187922,  0.01500382, ...,  0.10504436,\n        -0.06284735,  0.0051859 ],\n       [ 0.1323512 ,  0.01945285,  0.06376914, ...,  0.16973773,\n        -0.08150937, -0.08741213],\n       [ 0.09221309,  0.03286867, -0.05453553, ...,  0.01407232,\n         0.07919285, -0.13035272],\n       ...,\n       [ 0.05674529,  0.09535521,  0.10715585, ...,  0.02326189,\n         0.14302342,  0.04148311],\n       [-0.06244363, -0.07746019, -0.16216885, ..., -0.12061435,\n        -0.1706651 ,  0.15139966],\n       [ 0.02855223,  0.03102918,  0.17409141, ..., -0.0047065 ,\n        -0.17995022,  0.03680726]], dtype=float32), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)}], 'loss function': 'softmax_cross_entropy', 'eval metric': 'accuracy', 'optimizer': 'sgd'}"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch 1 => [train loss: 0.7876606113433838, train eval: 0.7415] | [val loss: 0.512567887878418, val eval: 0.8114]\nepoch 2 => [train loss: 0.4659649243036906, train eval: 0.82985] | [val loss: 0.42746301798820496, val eval: 0.8471]\nepoch 3 => [train loss: 0.40268772214253745, train eval: 0.8537833333333333] | [val loss: 0.41856889944076536, val eval: 0.8507]\nepoch 4 => [train loss: 0.375395339457194, train eval: 0.86365] | [val loss: 0.40838507976531985, val eval: 0.8537]\nepoch 5 => [train loss: 0.35098922929763793, train eval: 0.8714166666666666] | [val loss: 0.3852728305339813, val eval: 0.8615]\nepoch 6 => [train loss: 0.33924239934285483, train eval: 0.8741] | [val loss: 0.37799762868881226, val eval: 0.8641]\nepoch 7 => [train loss: 0.3237171047846476, train eval: 0.8806833333333334] | [val loss: 0.3633623619914055, val eval: 0.8712]\nepoch 8 => [train loss: 0.3117334505081177, train eval: 0.8859166666666667] | [val loss: 0.36610000853538516, val eval: 0.864]\nepoch 9 => [train loss: 0.3051723556836446, train eval: 0.8878833333333334] | [val loss: 0.35731758460998536, val eval: 0.8712]\nepoch 10 => [train loss: 0.29323127911885577, train eval: 0.8927833333333334] | [val loss: 0.352442264342308, val eval: 0.8752]\n"
    }
   ],
   "source": [
    "model.fit(num_epochs, train_iter, test_iter, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitd2lconda06445091a0e1459fa904aa9d0606f621",
   "display_name": "Python 3.7.6 64-bit ('d2l': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
