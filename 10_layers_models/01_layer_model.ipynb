{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layers and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tensorflow running on CPU\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from d2l.tensorflow import config, data, initializers, activations, losses, metrics, optimizers, plot\n",
    "\n",
    "config.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_iter, test_iter = data.load_tfds_dataset('fashion_mnist', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, learning_rate = 10, 0.5\n",
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "\n",
    "loss_function = losses.softmax_cross_entropy\n",
    "eval_metric = metrics.accuracy\n",
    "optimizer = optimizers.sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLayer:\n",
    "    _identifier = -1\n",
    "    __type__ = 'base'\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(BaseLayer):\n",
    "    def __init__(\n",
    "        self, n_inputs, n_outputs, activation='relu',\n",
    "        initialization='gaussian', magnitude=None, scale=None\n",
    "    ):\n",
    "        Dense.__type__ = 'compute'\n",
    "        Dense._identifier += 1\n",
    "        self.__name__ = '{}_{}'.format(Dense.__name__, Dense._identifier).lower()\n",
    "\n",
    "        self.weights, self.bias = initializers.initialize_parameters(\n",
    "            n_inputs, n_outputs, method=initialization, magnitude=magnitude, scale=scale\n",
    "        )\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.activation = activations.get_activation(activation)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str({\n",
    "            'name': self.__name__,\n",
    "            'type': self.__type__,\n",
    "            'n_inputs': self.n_inputs,\n",
    "            'n_outputs': self.n_outputs,\n",
    "            'activation': self.activation.__name__,\n",
    "            'weights': self.weights.numpy(),\n",
    "            'bias': self.bias.numpy()\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    _identifier = -1\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_function = None\n",
    "        self.eval_metric = None\n",
    "        self.eval_function = None\n",
    "        self.optimizer = None\n",
    "        self.compiled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(BaseModel):\n",
    "    def __init__(self):\n",
    "        super(Sequential, self).__init__()\n",
    "        Sequential._identifier += 1\n",
    "        self.__name__ = '{}_{}'.format(\n",
    "            Sequential.__name__, Sequential._identifier\n",
    "        ).lower()\n",
    "        self.layers = list()\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def compile(self, loss_function, eval_metric, optimizer):\n",
    "        self.loss_function = loss_function\n",
    "        self.eval_metric = eval_metric\n",
    "        self.optimizer = optimizer\n",
    "        self.compiled = True\n",
    "\n",
    "    def net(self, X, inference=False):\n",
    "        X = tf.reshape(X, (-1, self.layers[0].n_inputs))\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            X = layer.activation(tf.matmul(X, layer.weights) + layer.bias)\n",
    "\n",
    "        return tf.matmul(X, self.layers[-1].weights) + self.layers[-1].bias\n",
    "\n",
    "    def fit(self, epochs, train_iter, val_iter, learning_rate, batch_size, animate=False):\n",
    "        animator = None\n",
    "        if animate:\n",
    "            animator = plot.Animator(\n",
    "                xlabel='epoch', xlim=[1, epochs], ylim=[0, 1],\n",
    "                legend=['train loss', 'train eval', 'val loss', 'val eval'],\n",
    "                title='Training loss and eval'\n",
    "            )\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            metric_train = metrics.Accumulator(3)\n",
    "            W = [layer.weights for layer in self.layers]\n",
    "            b = [layer.bias for layer in self.layers]\n",
    "\n",
    "            for X, y in train_iter:\n",
    "                with tf.GradientTape() as t:\n",
    "                    y_hat = self.net(X)\n",
    "                    loss = self.loss_function(y, y_hat)\n",
    "                dW, db = t.gradient(loss, [W, b])\n",
    "                self.optimizer(W, b, dW, db, learning_rate, batch_size)\n",
    "                metric_train.add(\n",
    "                    tf.reduce_sum(loss), self.eval_metric(y, y_hat), y.shape[0]\n",
    "                )\n",
    "\n",
    "            train_metrics = (\n",
    "                metric_train[0] / metric_train[2],\n",
    "                metric_train[1] / metric_train[2]\n",
    "            )\n",
    "            val_metrics = self.predict(val_iter)\n",
    "            if animator:\n",
    "                animator.add(epoch + 1, train_metrics + val_metrics)\n",
    "            else:\n",
    "                print(\n",
    "                    'epoch {0} => '\n",
    "                    '[train loss: {1[0]}, train eval: {1[1]}]'\n",
    "                    ' | '\n",
    "                    '[val loss: {2[0]}, val eval: {2[1]}]'.format(\n",
    "                        epoch + 1, train_metrics, val_metrics\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    def predict(self, test_iter):\n",
    "        metric_test = metrics.Accumulator(3)\n",
    "\n",
    "        for X, y in test_iter:\n",
    "            y_hat = self.net(X, inference=True)\n",
    "            loss = self.loss_function(y, y_hat)\n",
    "            metric_test.add(tf.reduce_sum(loss), self.eval_metric(y, y_hat), y.shape[0])\n",
    "\n",
    "        return metric_test[0] / metric_test[2], metric_test[1] / metric_test[2]\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.compiled:\n",
    "            return str({\n",
    "                'name': self.__name__,\n",
    "                'layers': self.layers,\n",
    "                'loss function': self.loss_function.__name__,\n",
    "                'eval metric': self.eval_metric.__name__,\n",
    "                'optimizer': self.optimizer.__name__\n",
    "            })\n",
    "        return str({\n",
    "            'name': self.__name__,\n",
    "            'layers': self.layers,\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = Dense(num_inputs, num_hiddens)\n",
    "d1 = Dense(num_hiddens, num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': 'dense_0', 'type': 'compute', 'n_inputs': 784, 'n_outputs': 256, 'activation': 'relu', 'weights': array([[ 0.14725922,  0.07386696,  0.09464841, ...,  0.04962331,\n         0.03240259,  0.16276436],\n       [ 0.04921127,  0.12376031,  0.0893697 , ...,  0.13690081,\n        -0.02476264, -0.05755023],\n       [ 0.01736821, -0.03836132, -0.0116649 , ...,  0.09117223,\n        -0.05258843, -0.05509703],\n       ...,\n       [-0.09189288, -0.02289783, -0.00842697, ...,  0.01262701,\n        -0.11798956, -0.0248114 ],\n       [-0.15405217, -0.14964525, -0.00509485, ...,  0.08117805,\n         0.0152805 , -0.07696279],\n       [ 0.19414917, -0.12514627, -0.07362437, ..., -0.06660258,\n        -0.08112863, -0.11601476]], dtype=float32), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)}"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(d0)\n",
    "model.add(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': 'sequential_0', 'layers': [{'name': 'dense_0', 'type': 'compute', 'n_inputs': 784, 'n_outputs': 256, 'activation': 'relu', 'weights': array([[ 0.14725922,  0.07386696,  0.09464841, ...,  0.04962331,\n         0.03240259,  0.16276436],\n       [ 0.04921127,  0.12376031,  0.0893697 , ...,  0.13690081,\n        -0.02476264, -0.05755023],\n       [ 0.01736821, -0.03836132, -0.0116649 , ...,  0.09117223,\n        -0.05258843, -0.05509703],\n       ...,\n       [-0.09189288, -0.02289783, -0.00842697, ...,  0.01262701,\n        -0.11798956, -0.0248114 ],\n       [-0.15405217, -0.14964525, -0.00509485, ...,  0.08117805,\n         0.0152805 , -0.07696279],\n       [ 0.19414917, -0.12514627, -0.07362437, ..., -0.06660258,\n        -0.08112863, -0.11601476]], dtype=float32), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)}, {'name': 'dense_1', 'type': 'compute', 'n_inputs': 256, 'n_outputs': 10, 'activation': 'relu', 'weights': array([[ 2.02625748e-02, -7.67375603e-02, -7.78156519e-02, ...,\n        -7.97667578e-02, -4.36476842e-02, -7.24189281e-02],\n       [ 1.52483154e-02,  9.79197025e-02,  4.53089587e-02, ...,\n        -8.52066204e-02,  1.45019501e-01,  4.60478850e-02],\n       [ 9.20249373e-02,  2.95919012e-02,  1.18578749e-03, ...,\n         3.18481401e-02, -8.84861574e-02, -7.24751363e-03],\n       ...,\n       [ 1.17459660e-02,  4.90519889e-02, -1.92878358e-02, ...,\n         9.06936973e-02, -2.16867045e-01, -8.22401121e-02],\n       [-2.10716650e-01, -6.95667937e-02, -1.42243788e-01, ...,\n        -1.23181656e-01, -2.09575091e-02, -5.45685319e-03],\n       [ 8.25925097e-02,  1.86777934e-01, -8.51571313e-05, ...,\n         6.67742342e-02, -6.46346137e-02,  1.25868738e-01]], dtype=float32), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)}]}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss_function, eval_metric, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': 'sequential_0', 'layers': [{'name': 'dense_0', 'type': 'compute', 'n_inputs': 784, 'n_outputs': 256, 'activation': 'relu', 'weights': array([[ 0.14725922,  0.07386696,  0.09464841, ...,  0.04962331,\n         0.03240259,  0.16276436],\n       [ 0.04921127,  0.12376031,  0.0893697 , ...,  0.13690081,\n        -0.02476264, -0.05755023],\n       [ 0.01736821, -0.03836132, -0.0116649 , ...,  0.09117223,\n        -0.05258843, -0.05509703],\n       ...,\n       [-0.09189288, -0.02289783, -0.00842697, ...,  0.01262701,\n        -0.11798956, -0.0248114 ],\n       [-0.15405217, -0.14964525, -0.00509485, ...,  0.08117805,\n         0.0152805 , -0.07696279],\n       [ 0.19414917, -0.12514627, -0.07362437, ..., -0.06660258,\n        -0.08112863, -0.11601476]], dtype=float32), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)}, {'name': 'dense_1', 'type': 'compute', 'n_inputs': 256, 'n_outputs': 10, 'activation': 'relu', 'weights': array([[ 2.02625748e-02, -7.67375603e-02, -7.78156519e-02, ...,\n        -7.97667578e-02, -4.36476842e-02, -7.24189281e-02],\n       [ 1.52483154e-02,  9.79197025e-02,  4.53089587e-02, ...,\n        -8.52066204e-02,  1.45019501e-01,  4.60478850e-02],\n       [ 9.20249373e-02,  2.95919012e-02,  1.18578749e-03, ...,\n         3.18481401e-02, -8.84861574e-02, -7.24751363e-03],\n       ...,\n       [ 1.17459660e-02,  4.90519889e-02, -1.92878358e-02, ...,\n         9.06936973e-02, -2.16867045e-01, -8.22401121e-02],\n       [-2.10716650e-01, -6.95667937e-02, -1.42243788e-01, ...,\n        -1.23181656e-01, -2.09575091e-02, -5.45685319e-03],\n       [ 8.25925097e-02,  1.86777934e-01, -8.51571313e-05, ...,\n         6.67742342e-02, -6.46346137e-02,  1.25868738e-01]], dtype=float32), 'bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)}], 'loss function': 'softmax_cross_entropy', 'eval metric': 'accuracy', 'optimizer': 'sgd'}"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch 1 => [train loss: 0.7527556214650472, train eval: 0.7463833333333333] | [val loss: 0.5218812803268432, val eval: 0.8108]\nepoch 2 => [train loss: 0.45398745752970376, train eval: 0.83285] | [val loss: 0.435511593914032, val eval: 0.8427]\nepoch 3 => [train loss: 0.3964456132253011, train eval: 0.8545166666666667] | [val loss: 0.40081236295700073, val eval: 0.8565]\nepoch 4 => [train loss: 0.3665442253112793, train eval: 0.8658833333333333] | [val loss: 0.3912468364238739, val eval: 0.8578]\nepoch 5 => [train loss: 0.3482751040140788, train eval: 0.8727166666666667] | [val loss: 0.37469018261432646, val eval: 0.8688]\nepoch 6 => [train loss: 0.33423660310109454, train eval: 0.8781] | [val loss: 0.3691064363718033, val eval: 0.865]\nepoch 7 => [train loss: 0.31990981820424397, train eval: 0.88255] | [val loss: 0.3697754323959351, val eval: 0.864]\nepoch 8 => [train loss: 0.3060824718475342, train eval: 0.8871] | [val loss: 0.3689617602825165, val eval: 0.8647]\nepoch 9 => [train loss: 0.29575276635487874, train eval: 0.8915166666666666] | [val loss: 0.35730931198596955, val eval: 0.8694]\nepoch 10 => [train loss: 0.29284139092763267, train eval: 0.89265] | [val loss: 0.3545318542480469, val eval: 0.8697]\n"
    }
   ],
   "source": [
    "model.fit(num_epochs, train_iter, test_iter, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitd2lconda06445091a0e1459fa904aa9d0606f621",
   "display_name": "Python 3.7.6 64-bit ('d2l': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
