{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec:\n",
    "    def __init__(self):\n",
    "        self.embedding_vector = None\n",
    "        self.token_to_index = {}\n",
    "        self.index_to_token = {}\n",
    "        self.token_to_vector = {}\n",
    "    \n",
    "    def set_embedding_vector(self):\n",
    "        self.embedding_vector = np.stack(self.token_to_vector.values())\n",
    "    \n",
    "    def get_vecs_by_tokens(self, tokens):\n",
    "        vecs = []\n",
    "        for token in tokens:\n",
    "            vecs.append(self.token_to_vector[token])\n",
    "        return vecs\n",
    "\n",
    "glove_6b50d = Word2Vec()\n",
    "\n",
    "with open('../data/glove.6B.50d.txt', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        value = line.split(' ')\n",
    "        word = value[0]\n",
    "        coef = np.array(value[1:], dtype=np.float32)\n",
    "        glove_6b50d.token_to_vector[word] = coef\n",
    "        glove_6b50d.token_to_index[word] = i\n",
    "        glove_6b50d.index_to_token[i] = [word]\n",
    "    glove_6b50d.set_embedding_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(972, ['lives'])"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "glove_6b50d.token_to_index['investigation'], glove_6b50d.index_to_token[973]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(W, x, k):\n",
    "    # The added 1e-9 is for numerical stability\n",
    "    cos = np.dot(W, x.reshape((-1,))) / (\n",
    "        (np.sqrt(np.sum(W * W, axis=1) + 1e-9)) * np.sqrt(np.sum(x * x)))\n",
    "    topk = np.argsort(cos)[-k:]\n",
    "    return topk, [cos[i] for i in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    topk, cos = knn(\n",
    "        embed.embedding_vector,\n",
    "        embed.token_to_vector[query_token],\n",
    "        k+1\n",
    "    )\n",
    "    for i, c in zip(topk[1:], cos[1:]):  # Remove input words\n",
    "        print('cosine sim=%.3f: %s' % (c, (embed.index_to_token[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cosine sim=0.653: ['amazon.com']\ncosine sim=0.663: ['unbox']\ncosine sim=1.000: ['amazon']\n"
    }
   ],
   "source": [
    "get_similar_tokens('amazon', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cosine sim=0.800: ['boy']\ncosine sim=0.839: ['babies']\ncosine sim=1.000: ['baby']\n"
    }
   ],
   "source": [
    "get_similar_tokens('baby', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cosine sim=0.893: ['gorgeous']\ncosine sim=0.921: ['lovely']\ncosine sim=1.000: ['beautiful']\n"
    }
   ],
   "source": [
    "get_similar_tokens('beautiful', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(token_a, token_b, token_c, embed):\n",
    "    vecs = embed.get_vecs_by_tokens([token_a, token_b, token_c])\n",
    "    x = vecs[1] - vecs[0] + vecs[2]\n",
    "    topk, cos = knn(embed.embedding_vector, x, 1)\n",
    "    return embed.index_to_token[topk[0]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['girl']"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "get_analogy('man', 'woman', 'boy', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['tokyo']"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "get_analogy('china', 'beijing', 'japan', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['place']"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "get_analogy('bad', 'worst', 'nice', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['went']"
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "get_analogy('do', 'did', 'go', glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594823038175",
   "display_name": "Python 3.7.7 64-bit ('d2l': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
